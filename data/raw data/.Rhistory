swear.totals <- rbind(names(swear.grams[,1:28]), colSums(swear.grams[,1:28]))
setwd("/Users/kaylinwalker/Desktop/textmining_southpark_2/")
count.all <- read.csv("data/tidy data/southpark_tdm_all.csv", stringsAsFactors=FALSE)
# think up all the swear words they might use
swears <- c("fuck", "shit", "damn", "hell", "ass", "fatass", "asshole", "motherfucker",
"goddman", "goddamnit",  "smartass", "screwed", "screw", "screwing",
"goddamned","goddammit", "fucking", "fuckin", "damnit", "damned", "dammit", "bitch",
"bitches", "assholes", "asses")
swear.grams <- count.all[count.all$word %in% swears, ]
swear.totals <- rbind(names(swear.grams[,1:28]), colSums(swear.grams[,1:28]))
totes <- data.frame(t(rbind(totals, swear.totals[2,])))
totes
swear.totals
totals <- rbind(names(count.all[,1:28]), colSums(count.all[,1:28]))
totals
totes <- data.frame(t(rbind(totals, swear.totals[2,])))
colnames(totes) <- c("speaker", "total", "swears")
totes$total <- as.numeric(as.character(totes$total))
totes$swears <- as.numeric(as.character(totes$swears))
totes
overall <- round(sum(totes$swears)/sum(totes$total), 4)
# calculate the swearing rate per person
totes$swear.rate <- round(totes$swears/totes$total, 4)
# create the plot
totes <- totes[(totes$total > 3500 | totes$speaker=="Kenny" ) & totes$speaker!="All.others", ]
totes <- totes[order(-totes$swear.rate), ]
totes$speaker <- factor(totes$speaker, levels=totes$speaker)
mycolors <- c("#F5871F", "#C20631", "#cccccc", "#21B726", "#999999", "#673e1e",
"#266E35", "#666666", "#999999", "#5BE1C6", "#000000")
swearing <- ggplot(totes, aes(speaker, swear.rate*1000)) +
geom_bar(stat="identity", aes(fill=speaker)) +
geom_hline(yintercept=overall*1000, linetype="dashed") +
theme_classic() +
labs(title="Kenny Swears the Most per 1000 Words Spoken") +
ylab("Profanities per 1000 Words") +
xlab("") +
annotate("text", x=11, y=(overall*1000)+1, label="Average") +
scale_fill_manual(values = mycolors) +
geom_text(aes(x=speaker, y=(swear.rate*1000)-2, label=swear.rate*1000),
color="white", fontface="bold", size=6) +
theme(legend.position=1,plot.title = element_text(size=20),
axis.title.y=element_text(margin=margin(0,10,0,0)),
axis.text.x = element_text(angle = 15, hjust = 1))
swearing
mycolors <- c("#F5871F", "#C20631", "#cccccc", "#21B726", "#999999", "#673e1e",
"#266E35", "#04392c", "#fae2bc", "#5BE1C6", "#8d6798")
swearing <- ggplot(totes, aes(speaker, swear.rate*1000)) +
geom_bar(stat="identity", aes(fill=speaker)) +
geom_hline(yintercept=overall*1000, linetype="dashed") +
theme_classic() +
labs(title="Kenny Swears the Most per 1000 Words Spoken") +
ylab("Profanities per 1000 Words") +
xlab("") +
annotate("text", x=11, y=(overall*1000)+1, label="Average") +
scale_fill_manual(values = mycolors) +
geom_text(aes(x=speaker, y=(swear.rate*1000)-2, label=swear.rate*1000),
color="white", fontface="bold", size=6) +
theme(legend.position=1,plot.title = element_text(size=20),
axis.title.y=element_text(margin=margin(0,10,0,0)),
axis.text.x = element_text(angle = 15, hjust = 1))
swearing
mycolors <- c("#F5871F", "#C20631", "#cccccc", "#21B726", "#b7aa97", "#673e1e",
"#266E35", "#04392c", "#fae2bc", "#5BE1C6", "#8d6798")
swearing <- ggplot(totes, aes(speaker, swear.rate*1000)) +
geom_bar(stat="identity", aes(fill=speaker)) +
geom_hline(yintercept=overall*1000, linetype="dashed") +
theme_classic() +
labs(title="Kenny Swears the Most per 1000 Words Spoken") +
ylab("Profanities per 1000 Words") +
xlab("") +
annotate("text", x=11, y=(overall*1000)+1, label="Average") +
scale_fill_manual(values = mycolors) +
geom_text(aes(x=speaker, y=(swear.rate*1000)-2, label=swear.rate*1000),
color="white", fontface="bold", size=6) +
theme(legend.position=1,plot.title = element_text(size=20),
axis.title.y=element_text(margin=margin(0,10,0,0)),
axis.text.x = element_text(angle = 15, hjust = 1))
swearing
mycolors <- c("#F5871F", "#C20631", "#666666", "#21B726", "#b7aa97", "#673e1e",
"#266E35", "#04392c", "#fae2bc", "#5BE1C6", "#8d6798")
swearing <- ggplot(totes, aes(speaker, swear.rate*1000)) +
geom_bar(stat="identity", aes(fill=speaker)) +
geom_hline(yintercept=overall*1000, linetype="dashed") +
theme_classic() +
labs(title="Kenny Swears the Most per 1000 Words Spoken") +
ylab("Profanities per 1000 Words") +
xlab("") +
annotate("text", x=11, y=(overall*1000)+1, label="Average") +
scale_fill_manual(values = mycolors) +
geom_text(aes(x=speaker, y=(swear.rate*1000)-2, label=swear.rate*1000),
color="white", fontface="bold", size=6) +
theme(legend.position=1,plot.title = element_text(size=20),
axis.title.y=element_text(margin=margin(0,10,0,0)),
axis.text.x = element_text(angle = 15, hjust = 1))
swearing
mycolors <- c("#F5871F", "#C20631", "#760411", "#21B726", "#b7aa97", "#673e1e",
"#266E35", "#04392c", "#75bed1", "#5BE1C6", "#8d6798")
swearing <- ggplot(totes, aes(speaker, swear.rate*1000)) +
geom_bar(stat="identity", aes(fill=speaker)) +
geom_hline(yintercept=overall*1000, linetype="dashed") +
theme_classic() +
labs(title="Kenny Swears the Most per 1000 Words Spoken") +
ylab("Profanities per 1000 Words") +
xlab("") +
annotate("text", x=11, y=(overall*1000)+1, label="Average") +
scale_fill_manual(values = mycolors) +
geom_text(aes(x=speaker, y=(swear.rate*1000)-2, label=swear.rate*1000),
color="white", fontface="bold", size=6) +
theme(legend.position=1,plot.title = element_text(size=20),
axis.title.y=element_text(margin=margin(0,10,0,0)),
axis.text.x = element_text(angle = 15, hjust = 1))
swearing
dev.copy(png, 'plots/southpark_swearsalot_plot.png')
dev.off()
library(wordcloud)
setwd("/Users/kaylinwalker/Desktop/textmining_southpark_2/")
count.all <- read.csv("data/tidy data/southpark_tdm_all.csv", stringsAsFactors=FALSE)
findFreq <- function(df){
df$total <- rowSums(df[,1:28])
freqs <- df[,29:30]
freqs <- freqs[order(-freqs$total), ]
return(freqs)
}
freq1 <- findFreq(count.all)
cloud <- wordcloud(freq1$word, freq1$total, scale=c(2.5, 0.3), min.freq=100, max.words=250, random.order=FALSE)
dev.copy(cloud,'plots/southpark_wordcloud.png')
dev.copy(png,'plots/southpark_wordcloud.png')
dev.off()
library(ggplot2)
library(RColorBrewer)
library(png)
library(grid)
setwd("/Users/kaylinwalker/Desktop/textmining_southpark_2/")
count.all <- read.csv("tidy data/southpark_tdm_all.csv", stringsAsFactors=FALSE)
# function to get the log likelihood of each of a
# speaker's words vs. the rest of the dataframe
LL.all <- function(df, speaker) {
LL.df <- NULL
for(word in seq_along(df[,1])) {
word <- df$word[word]
speaker.sums <- data.frame(speaker = names(colSums(df[,1:28])) , total=colSums(df[,1:28]), row.names=NULL)
word.sums <- data.frame(word = df$word , total=rowSums(df[ ,1:28]), row.names=NULL)
all.words.total <- sum(speaker.sums$total)
word.total <- word.sums[word.sums$word==word, 2]
speaker.total <- speaker.sums[speaker.sums$speaker==speaker, 2]
if(speaker.total == 0) speaker.total <- 0.0001
other.total <- all.words.total - speaker.total
speaker.word <- df[df$word==word, ]
speaker.word <- data.frame(speaker=names(speaker.word), count=t(speaker.word), row.names=NULL)
speaker.word <- as.numeric(as.character(speaker.word[speaker.word$speaker==speaker, 2]))
other.word <- word.total - speaker.word
if(speaker.word == 0) speaker.word <- 0.0001
E1 <- (speaker.total*word.total)/all.words.total
E2 <- (other.total*word.total)/all.words.total
LL <- 2*(speaker.word*log(speaker.word/E1) + other.word*log(other.word/E2))
if(abs(LL) > 10.83) {
if(E1 > speaker.word) LL <- -1*LL
speaker.word <- round(speaker.word)
speaker.total <- round(speaker.total)
row <- data.frame(speaker, word, word.total, speaker.total, speaker.word, E1, E2, LL)
LL.df <- rbind(LL.df, row)
}
}
LL.df <- LL.df[order(-LL.df$LL), ]
return(LL.df)
}
# create a staging function to pass a speaker at a time through the LL function
LL_pass <- function(df, threshold) {
output <- NULL
df <- df[rowSums(df[,1:28]) > threshold, ]
people <- colnames(df[,c(1:(length(df[1,])-1))])
for(person in people) {
temp.p <- subset(df, select=person)
temp.count <- subset(df, select=word)
temp.w <- cbind(temp.p, temp.count)
temp <- LL.all(df=df, speaker=person)
output <- rbind(output, temp)
}
return(output)
}
?dev.copy
library(wordcloud)
setwd("/Users/kaylinwalker/Desktop/textmining_southpark_2/")
count.all <- read.csv("data/tidy data/southpark_tdm_all.csv", stringsAsFactors=FALSE)
findFreq <- function(df){
df$total <- rowSums(df[,1:28])
freqs <- df[,29:30]
freqs <- freqs[order(-freqs$total), ]
return(freqs)
}
freq1 <- findFreq(count.all)
cloud <- wordcloud(freq1$word, freq1$total, scale=c(2.5, 0.3), min.freq=100, max.words=250, random.order=FALSE)
dev.copy(png,'plots/southpark_wordcloud.png', height=4, width=4)
dev.print(height=4, width=4)
dev.copy(png,'plots/southpark_wordcloud.png')
dev.off()
cloud <- wordcloud(freq1$word, freq1$total, scale=c(4,1), min.freq=100, max.words=250, random.order=FALSE)
cloud <- wordcloud(freq1$word, freq1$total, scale=c(3,1), min.freq=100, max.words=250, random.order=FALSE)
cloud <- wordcloud(freq1$word, freq1$total, scale=c(3,0.5), min.freq=100, max.words=250, random.order=FALSE)
setwd("/Users/kaylinwalker/Desktop/textmining_southpark_2/")
ngrams <- read.csv("data/tidy data/southpark_tdm_all.csv", stringsAsFactors=FALSE)
cloud <- wordcloud(freq1$word, freq1$total, scale=c(2.5,0.5), min.freq=100, max.words=250, random.order=FALSE)
cloud <- wordcloud(freq1$word, freq1$total, scale=c(2.5,0.5), min.freq=100, max.words=200, random.order=FALSE)
library(ggplot2)
library(RColorBrewer)
setwd("/Users/kaylinwalker/Desktop/textmining_southpark_2/")
count.all <- read.csv("data/tidy data/southpark_tdm_all.csv", stringsAsFactors=FALSE)
totals <- rbind(names(count.all[,1:28]), colSums(count.all[,1:28]))
total <- data.frame(t(totals))
colnames(total) <- c("speaker", "total")
total$total <- as.numeric(as.character(total$total))
small <- total[total$total < 10000 | total$speaker=="All.others", ]
row <- data.frame(speaker="All.others", total=sum(small$total))
total <- rbind(total[total$total >= 10000 & total$speaker!="All.others", ], row)
# get the average words per episode, assuming that the main speakers are in each
total$per.Episode <- round(as.numeric(as.character(total$total))/264, 2)
total <- total[order(-total$per.Episode), ]
total$share <- round(total$per.Episode/sum(total$per.Episode), 3)*100
# make the plot
total$speaker <- factor(total$speaker, levels=c("All.others", "Cartman", "Stan", "Kyle", "Randy", "Butters"))
total$group <- " "
mycolors <- c("#666666", "#C20631", "#673e1e",  "#21B726", "#266E35", "#5BE1C6")
wordshare <- ggplot(total, aes(group,share)) +
geom_bar(stat="identity", aes(fill=speaker)) +
theme_classic() + labs(title="Cartman Talks the Most") +
ylab("Share of Words Spoken per Episode (Avg. %)") +
scale_fill_manual(values = mycolors[1:6]) + xlab("") +
theme(legend.position=1,plot.title = element_text(size=18),
axis.title.y=element_text(margin=margin(0,10,0,0))) +
geom_text(aes(x=group, y=cumsum(share)-share*0.5,
label=paste(speaker,": ",share,"%", sep="")),
color="white", fontface="bold", size=4)
wordshare
source('~/Desktop/textmining_southpark_2/scripts/southpark_plot_swearingrate.R', echo=TRUE)
library(ggplot2)
library(RColorBrewer)
setwd("/Users/kaylinwalker/Desktop/textmining_southpark_2/")
count.all <- read.csv("data/tidy data/southpark_tdm_all.csv", stringsAsFactors=FALSE)
# think up all the swear words they might use
swears <- c("fuck", "shit", "damn", "hell", "ass", "fatass", "asshole", "motherfucker",
"goddman", "goddamnit",  "smartass", "screwed", "screw", "screwing",
"goddamned","goddammit", "fucking", "fuckin", "damnit", "damned", "dammit", "bitch",
"bitches", "assholes", "asses")
# subset the unigram .csv
swear.grams <- count.all[count.all$word %in% swears, ]
swear.totals <- rbind(names(swear.grams[,1:28]), colSums(swear.grams[,1:28]))
totals <- rbind(names(count.all[,1:28]), colSums(count.all[,1:28]))
totes <- data.frame(t(rbind(totals, swear.totals[2,])))
colnames(totes) <- c("speaker", "total", "swears")
totes$total <- as.numeric(as.character(totes$total))
totes$swears <- as.numeric(as.character(totes$swears))
# calculate the overall rate of swearing
overall <- round(sum(totes$swears)/sum(totes$total), 4)
# calculate the swearing rate per person
totes$swear.rate <- round(totes$swears/totes$total, 4)
# create the plot
totes <- totes[(totes$total > 3500 | totes$speaker=="Kenny" ) & totes$speaker!="All.others", ]
totes <- totes[order(-totes$swear.rate), ]
totes$speaker <- factor(totes$speaker, levels=totes$speaker)
mycolors <- c("#F5871F", "#C20631", "#760411", "#21B726", "#b7aa97", "#673e1e",
"#266E35", "#04392c", "#75bed1", "#5BE1C6", "#8d6798")
swearing <- ggplot(totes, aes(speaker, swear.rate*1000)) +
geom_bar(stat="identity", aes(fill=speaker)) +
geom_hline(yintercept=overall*1000, linetype="dashed") +
theme_classic() +
labs(title="Kenny Swears the Most per 1000 Words Spoken") +
ylab("Profanities per 1000 Words") +
xlab("") +
annotate("text", x=11, y=(overall*1000)+1, label="Average") +
scale_fill_manual(values = mycolors) +
geom_text(aes(x=speaker, y=(swear.rate*1000)-2, label=swear.rate*1000),
color="white", fontface="bold", size=6) +
theme(legend.position=1,plot.title = element_text(size=20),
axis.title.y=element_text(margin=margin(0,10,0,0)),
axis.text.x = element_text(angle = 15, hjust = 1))
swearing
swearing <- ggplot(totes, aes(speaker, swear.rate*1000)) +
geom_bar(stat="identity", aes(fill=speaker)) +
geom_hline(yintercept=overall*1000, linetype="dashed") +
theme_classic() +
labs(title="Kenny Swears at the Highest Rate") +
ylab("Profanities per 1000 Words") +
xlab("") +
annotate("text", x=11, y=(overall*1000)+1, label="Average") +
scale_fill_manual(values = mycolors) +
geom_text(aes(x=speaker, y=(swear.rate*1000)-2, label=swear.rate*1000),
color="white", fontface="bold", size=6) +
theme(legend.position=1,plot.title = element_text(size=20),
axis.title.y=element_text(margin=margin(0,10,0,0)),
axis.text.x = element_text(angle = 15, hjust = 1))
swearing
ggplot(totes, aes(speaker, swear.rate*1000)) +
geom_bar(stat="identity", aes(fill=speaker)) +
geom_hline(yintercept=overall*1000, linetype="dashed") +
theme_classic() +
labs(title="Kenny Swears at the Highest Rate") +
ylab("Profanities per 1000 Words") +
xlab("") +
annotate("text", x=11, y=(overall*1000)+1, label="Average") +
scale_fill_manual(values = mycolors) +
geom_text(aes(x=speaker, y=(swear.rate*1000)-2, label=swear.rate*1000),
color="white", fontface="bold", size=6) +
theme(legend.position=1,plot.title = element_text(size=20),
axis.title.y=element_text(margin=margin(0,10,0,0)),
axis.text.x = element_text(angle = 15, hjust = 1, size=12))
library(ggplot2)
library(RColorBrewer)
library(png)
library(grid)
setwd("/Users/kaylinwalker/Desktop/textmining_southpark_2/")
count.all <- read.csv("tidy data/southpark_tdm_all.csv", stringsAsFactors=FALSE)
# function to get the log likelihood of each of a
# speaker's words vs. the rest of the dataframe
LL.all <- function(df, speaker) {
LL.df <- NULL
for(word in seq_along(df[,1])) {
word <- df$word[word]
speaker.sums <- data.frame(speaker = names(colSums(df[,1:28])) , total=colSums(df[,1:28]), row.names=NULL)
word.sums <- data.frame(word = df$word , total=rowSums(df[ ,1:28]), row.names=NULL)
all.words.total <- sum(speaker.sums$total)
word.total <- word.sums[word.sums$word==word, 2]
speaker.total <- speaker.sums[speaker.sums$speaker==speaker, 2]
if(speaker.total == 0) speaker.total <- 0.0001
other.total <- all.words.total - speaker.total
speaker.word <- df[df$word==word, ]
speaker.word <- data.frame(speaker=names(speaker.word), count=t(speaker.word), row.names=NULL)
speaker.word <- as.numeric(as.character(speaker.word[speaker.word$speaker==speaker, 2]))
other.word <- word.total - speaker.word
if(speaker.word == 0) speaker.word <- 0.0001
E1 <- (speaker.total*word.total)/all.words.total
E2 <- (other.total*word.total)/all.words.total
LL <- 2*(speaker.word*log(speaker.word/E1) + other.word*log(other.word/E2))
if(abs(LL) > 10.83) {
if(E1 > speaker.word) LL <- -1*LL
speaker.word <- round(speaker.word)
speaker.total <- round(speaker.total)
row <- data.frame(speaker, word, word.total, speaker.total, speaker.word, E1, E2, LL)
LL.df <- rbind(LL.df, row)
}
}
LL.df <- LL.df[order(-LL.df$LL), ]
return(LL.df)
}
# create a staging function to pass a speaker at a time through the LL function
LL_pass <- function(df, threshold) {
output <- NULL
df <- df[rowSums(df[,1:28]) > threshold, ]
people <- colnames(df[,c(1:(length(df[1,])-1))])
for(person in people) {
temp.p <- subset(df, select=person)
temp.count <- subset(df, select=word)
temp.w <- cbind(temp.p, temp.count)
temp <- LL.all(df=df, speaker=person)
output <- rbind(output, temp)
}
return(output)
}
# pass the words through the log likelihood function
#### FYI: this takes a while.
allLL <- LL_pass(count.all, 25)
write.csv(allLL, "tidy data/southpark_ngrams.csv", row.names=FALSE)
write.csv(allLL, "data/tidy data/southpark_ngrams.csv", row.names=FALSE)
ngrams <- allLL[abs(allLL$LL) >= 10.83, ]
n.unique <- function(df){
ngrams.unique <- NULL
words <- unique(df$word)
for(h in seq_along(words)) {
subset <- df[df$word==words[h],]
if(length(subset[,1]) > 1) subset <- subset[order(-abs(subset$LL)), ]
ngrams.unique <- rbind(ngrams.unique, subset[1,])
}
return(ngrams.unique)
}
ngrams.unique <- rbind(n.unique(ngrams[ngrams$LL >= 0, ]),
n.unique(ngrams[ngrams$LL < 0, ]))
# keep just main speakers
main.speakers <- c("Cartman", "Stan", "Kyle", "Kenny", "Butters", "Randy")
plot <- allLL[allLL$speaker %in% main.speakers, ]
# remove phrases like 'ha ha' and 'you you'
plot <- plot[!grepl("\\b(\\w+)\\s\\1\\b", plot$word, perl=TRUE), ]
# split by speaker, rank by log likelihood  * ngram length, keep the top 25
rankbyspeaker <- function(df, direction) {
rank <- NULL
speakers <- unique(df$speaker)
for(j in speakers) {
subset <- df[df$speaker==j,]
subset$ngram <- sapply(subset$word, function(x) length(strsplit(as.character(x), " ")[[1]]))
subset$rank <- subset$LL*subset$ngram
subset <- subset[order(-subset$rank),]
if(length(subset[,1]) > 25) subset <- subset[1:25,]
row.names(subset) <- NULL
subset$rank2 <- as.numeric(row.names(subset))
rank <- rbind(rank, subset)
}
return(rank)
}
ranked <- rankbyspeaker(plot)
ranked <- ranked[order(-ranked$speaker.total), ]
ranked$speaker <- factor(ranked$speaker, levels=c('Cartman', 'Stan', 'Kyle','Kenny',
'Butters', 'Randy'))
# generate plot
ec <- readPNG("plots/images/cartman.png"); cartman <- rasterGrob(ec, interpolate=TRUE)
sm <- readPNG("plots/images/stan.png"); stan <- rasterGrob(sm, interpolate=TRUE)
km <- readPNG("plots/images/kenny.png"); kenny <- rasterGrob(km, interpolate=TRUE)
kb <- readPNG("plots/images/kyle.png"); kyle <- rasterGrob(kb, interpolate=TRUE)
mg <- readPNG("plots/images/randy.png"); randy <- rasterGrob(mg, interpolate=TRUE)
bs <- readPNG("plots/images/butters.png"); butters <- rasterGrob(bs, interpolate=TRUE)
mycolors <- c("#C20631", "#673e1e", "#21B726", "#F5871F", "#5BE1C6", "#266E35")
ggplot(ranked, aes(speaker, ((rank2*-1)-4))) +
geom_point(color="white") +
geom_label(aes(label=ranked$word,fill=ranked$speaker), color='white', fontface='bold', size=5) +
scale_fill_manual(values = mycolors) +
theme_classic() +
theme(legend.position=1,plot.title = element_text(size=18), axis.title.y=element_text(margin=margin(0,10,0,0))) +
labs(title="Most Characteristic Words/Phrases per Person") +
xlab("") + ylab("Ranking") +
scale_y_continuous(limits=c(-29,-1), breaks=c(-24, -14, -4.5), labels=c("#20", "#10", "#1")) +
annotation_custom(cartman, xmin=.5, xmax=1.5, ymin=0, ymax=-4) +
annotation_custom(stan, xmin=1.5, xmax=2.5, ymin=0, ymax=-4) +
annotation_custom(kyle, xmin=2.5, xmax=3.5, ymin=0, ymax=-4) +
annotation_custom(kenny, xmin=3.5, xmax=4.5, ymin=0, ymax=-4) +
annotation_custom(butters, xmin=4.5, xmax=5.5, ymin=0, ymax=-4) +
annotation_custom(randy, xmin=5.5, xmax=6.5, ymin=0, ymax=-4)
setwd("/Users/kaylinwalker/Desktop/textmining_southpark_2/")
ngrams <- read.csv("data/tidy data/southpark_ngrams.csv", stringsAsFactors=FALSE)
head(ngrams)
count <- ngrams[ ,c(2,3)]
count <- count[!duplicated(count),]
head(count)
sum(count$word.total)
count.all <- read.csv("data/tidy data/southpark_tdm_all.csv", stringsAsFactors=FALSE)
head(count.all)
sum(colSums(count.all[,1:28]))
setwd("/Users/kaylinwalker/Desktop/textmining_southpark_2/data/raw data")
scripts <- read.csv("all-seasons.csv", stringsAsFactors=FALSE)
object.size(scripts)
massive <- str_c(scripts$Line, collapse=" ")
library("stringr")
massive <- str_c(scripts$Line, collapse=" ")
un <- unique(massive)
length(un)
length(strsplit(un, " ")[[1]])
massive <- gsub("[[:punct:]]", "", massive)
massive <- tolower(massive)
length(strsplit(unique(massive), " ")[[1]])
massive[1:2]
substr(massive, 1, 10)
massive <- gsub("\\n", "", massive)
un <- unique(massive)
length(strsplit(massive, " ")[[1]])
split <- strsplit(as.character(massive), " ")
length(split)
length(split[[1]])
split[[1]][1:5]
uni <- unique(split)
uni[[1]][1:5]
str(uni)
unlist(split)
length(split)
split <- unlist(split)
length(split)
length(unique(split))
head(count.all)
length(unique(allLL$word))
length(unique(scripts$Character))
3987-29
head(ngrams)
characters <- unique(ngrams$speaker)
characters
character <- characters[5]
character <- characters[8]
b <- ngrams[ngrams$speaker==character, ]
b <- b[1, c(1,4)]
b
for(character in characters){
b <- ngrams[ngrams$speaker==character, ]
b <- b[1, c(1,4)]
chars <- rbind(chars, b)
}
total <- sum(chars$speaker.total)
chars <- NULL
for(character in characters){
b <- ngrams[ngrams$speaker==character, ]
b <- b[1, c(1,4)]
chars <- rbind(chars, b)
}
charws
chars
total <- sum(chars$speaker.total)
chars$word.share <- round(chars$speaker.total/total,2)
chars <- chars[order(-chars$speaker.total), ]
head(chars)
chars <- chars[c(2:27,1),]
chars
chars$speaker <- factor(chars$speaker, levels=chars$speaker)
colnames(chars) <- c("speaker", "words")
chars$speaker <- tolower(chars$speaker)
charsk <- cbind(chars[1:9,1:2], chars[10:17,1:2], chars[18:27,1:2])
charsk <- cbind(chars[1:9,1:2], chars[10:19,1:2], chars[20:27,1:2])
charsk <- cbind(chars[1:9,1:2], chars[10:18,1:2], chars[19:27,1:2])
kable(charsk, row.names=FALSE, caption="Number of Words by Character")
find_sig <- function(level) {
ngrams$sig <- FALSE
for(h in seq_along(ngrams[,1])) if(ngrams$LL[h] > level) ngrams$sig[h] <- TRUE
siglevel <- data.frame(table(ngrams$sig))
sigpercent <- round(siglevel$Freq[2]/sum(siglevel$Freq), 4)*100
return(sigpercent)
}
logl <- data.frame(Level=c("5%", "1%", "0.1%", "0.01%"),
Critical.Value=c(3.84, 6.63, 10.83, 15.13),
p.Value=c("0.05", "0.01", "0.001", "0.0001"))
for(h in 1:4) logl$Percent.Sig[h] <- find_sig(logl$Critical.Value[h])
